---
title: "AI Survey Analysis_whole questionnaire0926"
author: "Ujjayini Das"
date: "2025-09-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
pacman::p_load(lavaan,lavaan.survey,semTools,tidyverse,survey,ggplot2,brms,rstan,ordinal,boot,readxl,xlsx,polycor,psych,gridExtra,RColorBrewer,reshape2,xtable,mice,scales,srvyr,rstatix)
```

## Read the data 
df1 = read.csv("Data/final_AI_data.csv")
m = vector(mode = "list", length = 17)
## fitting the model to our survey data ##
for(i in 1:17){
  m[[i]] = MASS::polr(df1[,i] ~ Race+Hispanic+Age+Sup+Fed+Sex, method = "logistic", data = df1)
}
```


## Prediction of Y in FEVS

```{r}
df_FEVS = read_excel("Data/FEVS 2023 snippet.xlsx")

### Preprocessing
df_FEVS = df_FEVS %>%
  mutate(Age = recode_factor(DAGEGRP, `A` = "1", `B` = "2"),
         Sup = recode_factor(DSUPER, `A` = "1", `B` = "2"),
         Fed = recode_factor(DFEDTEN, `A` ="1", `B`= "2", `C` = "3"),
         Sex = recode_factor(DSEX, `A` = "1", `B`= "2"),
         Hispanic = recode_factor(DHISP, `A` = "2", `B` = "1"),
         Race = recode_factor(DRNO, `A` = "2", `B` = "1", `C` = "4", `D` = "4")) %>%
  select(Age,Sup, Fed, Sex,Hispanic, Race, POSTWT,agency) %>%
  mutate(ID = 1:nrow(.))
df_FEVS_pred = df_FEVS
for(i in 1:17){
 df_FEVS_pred = cbind(df_FEVS_pred, predict(m[[i]], df_FEVS)) 
}
names(df1)[16] = "factors regarding agencys success - Gauging the comfort level of the clients with the use of AI technologies"
colnames(df_FEVS_pred) = make.names(c(names(df_FEVS),paste0("y_", names(df1[,1:17]))))

```


## cfa with ordinal data
```{r}
cfa_model = '
  Fluency =~ y_clear_explanation + y_security_measure + y_accountability + y_privacy + y_Knowledgeable.employee + y_Partnerships.with.AI.solutions.providers.and.consultants
  Adoption =~ y_hindrace.to.AI.adoption...Implementation.costs.of.AI.solutions + y_hindrace.to.AI.adoption...Integration.challenges.with.existing.infrastructure + y_hindrace.to.AI.adoption...Reputational.risks + y_hindrace.to.AI.adoption...Access.to.external.data + y_hindrace.to.AI.adoption...Sponsorship.from.agency.leadership + y_Governance.Program + y_factors.regarding.agencys.success...Gauging.the.comfort.level.of.the.clients.with.the.use.of.AI.technologies
  Adaptation =~ y_Budget.optimisation + y_Better.services.to.our.clients + y_responsive.to.oversight.requests + y_Impact.on.strategic.focus

  
  Fluency ~~ Adoption
  Adoption ~~ Adaptation
  Adaptation ~~ Fluency
'
ordered_items = names(df_FEVS_pred)[9:25]
cfa_model_fit_noweight = cfa(cfa_model,
                 data = df_FEVS_pred,
                 ordered = ordered_items,
                 estimator = "WLSMV",
                 missing = "pairwise")  # WLSMV doesn't use FIML

summary(cfa_model_fit_noweight, fit.measures = TRUE, standardized = TRUE)



## Checking for alternative covariances to be included in the model to decrease chi-square by 100000
fit_check1=modindices(cfa_model_fit_noweight,minimum.value = 100000, sort = TRUE)
write.csv(fit_check1,"Data/fit_check1.csv")

cfa_model_2 = '
  Fluency =~ y_clear_explanation + y_security_measure + y_accountability + y_privacy + y_Knowledgeable.employee + y_Partnerships.with.AI.solutions.providers.and.consultants
  Adoption =~ y_hindrace.to.AI.adoption...Implementation.costs.of.AI.solutions + y_hindrace.to.AI.adoption...Integration.challenges.with.existing.infrastructure + y_hindrace.to.AI.adoption...Reputational.risks + y_hindrace.to.AI.adoption...Access.to.external.data + y_hindrace.to.AI.adoption...Sponsorship.from.agency.leadership + y_Governance.Program + y_factors.regarding.agencys.success...Gauging.the.comfort.level.of.the.clients.with.the.use.of.AI.technologies+y_clear_explanation
  Adaptation =~ y_Budget.optimisation + y_Better.services.to.our.clients + y_responsive.to.oversight.requests + y_Impact.on.strategic.focus
  y_clear_explanation ~~ y_privacy
  y_clear_explanation ~~ y_accountability
  y_Budget.optimisation ~~ y_Better.services.to.our.clients
  y_hindrace.to.AI.adoption...Implementation.costs.of.AI.solutions ~~ y_hindrace.to.AI.adoption...Integration.challenges.with.existing.infrastructure
  y_hindrace.to.AI.adoption...Reputational.risks ~~ y_Governance.Program
  y_security_measure ~~ y_Governance.Program
  y_privacy ~~ y_Governance.Program
  
  Fluency ~~ Adoption
  Adoption ~~ Adaptation
  Adaptation ~~ Fluency'

cfa_model_fit_2 = cfa(cfa_model_2,
                 data = df_FEVS_pred,
                 ordered = ordered_items,
                 estimator = "WLSMV",
                 missing = "pairwise")  # WLSMV doesn't use FIML

summary(cfa_model_fit_2, fit.measures = TRUE, standardized = TRUE)

fit_check2=modindices(cfa_model_fit_2,minimum.value = 100000, sort = TRUE)
write.csv(fit_check2,"Data/fit_check2.csv")

```


## Calculating positive and negative response %s

```{r}
pos_7 =function(df){
  for(i in 1:ncol(df)){
    df[,i] = ifelse(df[,i] %in% c(5:7),1,0)
  }
  return(df)
}
df_FEVS_pred_7 = df_FEVS_pred[,c(10:13,19:24)]  
df_FEVS_pred_7 = pos_7(df_FEVS_pred_7)

pos_5 =function(df){
  for(i in 1:ncol(df)){
    df[,i] = ifelse(df[,i] %in% c(4:5),1,0)
  }
  return(df)
}
df_FEVS_pred_5 = df_FEVS_pred[,c(25:26)]  
df_FEVS_pred_5 = pos_5(df_FEVS_pred_5)

pos_3 =function(df){
  for(i in 1:ncol(df)){
    df[,i] = ifelse(df[,i] %in% c(1:2),1,0)
  }
  return(df)
}
df_FEVS_pred_3 = df_FEVS_pred[,c(14:18)]  
df_FEVS_pred_3 = pos_3(df_FEVS_pred_3)

df_FEVS_pred_index = data.frame(df_FEVS_pred[,7:8], df_FEVS_pred_7, df_FEVS_pred_5, df_FEVS_pred_3)



group_qs = list(
  "Fluency" = names(df_FEVS_pred_index)[c(3:6,8:9)],
  "Adoption" = names(df_FEVS_pred_index)[c(3,7,13,15:19)],
  "Adaptation" = names(df_FEVS_pred_index)[c(10:12,14)]
)
weight = names(df_FEVS_pred_index)[1]

lookup_index = tibble(
  variable = unlist(group_qs, use.names = FALSE),
  group = rep(names(group_qs), lengths(group_qs))
)

# ---------- Per-variable weighted percentage (0/1 variables) for overall population ----------
pos_pct = df_FEVS_pred_index %>%
  # keep only variables that are in lookup 
  select(all_of(c(lookup_index$variable, weight))) %>%
  pivot_longer(cols = -all_of(weight), names_to = "variable", values_to = "response") %>%
  left_join(lookup_index, by = "variable") %>%
  group_by(group, variable) %>%
  summarise(
    weighted_pct = weighted.mean(response, .data[[weight]], na.rm = TRUE) * 100,
    .groups = "drop"
  ) %>%
  arrange(group, variable)

pos_pct

## ------ fluency, adoption, adaptation scores for overall population ---------

overall_scores = pos_pct %>%
  group_by(group) %>%
  summarise(`percentage of positive perception` = round(mean(weighted_pct),1))
```

### Fluency, adoption and adaptation scores by demographics ####

```{r}
df_FEVS_pred_index = cbind(df_FEVS_pred_index,df_FEVS_pred[,1:3])
df_FEVS_pred_index = df_FEVS_pred_index %>%
  mutate(fluency_score = rowSums(df_FEVS_pred_index[,c(3:6,8:9)]),
         adoption_score = rowSums(df_FEVS_pred_index[,c(3,7,13,15:19)]),
         adaptation_score = rowSums(df_FEVS_pred_index[,c(10:12,14)]))
overall_scores_age = df_FEVS_pred_index %>%
  group_by(Age) %>%
  summarise(`Fluency score` = round(weighted.mean(fluency_score, POSTWT, na.rm = TRUE),1),
            `Adoption score` = round(weighted.mean(adoption_score, POSTWT, na.rm = TRUE),1),
            `Adaptation score` = round(weighted.mean(adaptation_score, POSTWT, na.rm = TRUE),1),
            .groups = "drop") 
overall_scores_age = overall_scores_age[-3,]
overall_scores_fed = df_FEVS_pred_index %>%
  group_by(Fed) %>%
  summarise(`Fluency score` = round(weighted.mean(fluency_score, POSTWT, na.rm = TRUE),1),
            `Adoption score` = round(weighted.mean(adoption_score, POSTWT, na.rm = TRUE),1),
            `Adaptation score` = round(weighted.mean(adaptation_score, POSTWT, na.rm = TRUE),1),
            .groups = "drop") 
overall_scores_fed = overall_scores_fed[-4,]
overall_scores_sup = df_FEVS_pred_index %>%
  group_by(Sup) %>%
  summarise(`Fluency score` = round(weighted.mean(fluency_score, POSTWT, na.rm = TRUE),1),
            `Adoption score` = round(weighted.mean(adoption_score, POSTWT, na.rm = TRUE),1),
            `Adaptation score` = round(weighted.mean(adaptation_score, POSTWT, na.rm = TRUE),1),
            .groups = "drop") 
overall_scores_sup = overall_scores_sup[-3,]

## By agency
overall_scores_agency = df_FEVS_pred_index %>%
  group_by(agency) %>%
  summarise(`Fluency score` = round(weighted.mean(fluency_score, POSTWT, na.rm = TRUE),1),
            `Adoption score` = round(weighted.mean(adoption_score, POSTWT, na.rm = TRUE),1),
            `Adaptation score` = round(weighted.mean(adaptation_score, POSTWT, na.rm = TRUE),1),
            .groups = "drop") 
agency_code= read.csv("Data/agency_codebook_updated.csv") %>%
  dplyr::select(c(1:3,5))
overall_scores_agency= merge(overall_scores_agency,agency_code, by.x="agency", by.y="CODE")

```


### Measuring Impact from Fluency, Adoption and Adaptation

```{r}
# ----- PCA ------- 
impact_index= df_FEVS_pred_index[,c(1:2,20:25)]

pca1= prcomp(impact_index[,6:8], scale. = TRUE, center = TRUE)
pca1

#------ SEM ------
model_impact = 'adoption_score ~ b12*fluency_score
                adaptation_score ~ b23*adoption_score'  
fit_impact = sem(model_impact, data = impact_index[,6:8], std.lv = FALSE)
summary(fit_impact, standardized = TRUE)
std_est_impact = standardizedsolution(fit_impact)
b12 = std_est_impact$est.std[std_est_impact$lhs=="adoption_score" & std_est_impact$rhs == "fluency_score"]
b23 = std_est_impact$est.std[std_est_impact$lhs=="adaptation_score" & std_est_impact$rhs == "adoption_score"]
w1 = b12*b23 # effect of fluency on adaptation
w2 = b23 # effect of adoption on adaptation
w3 = 1 # effect of adaptation on itself
### normalized weights
w_sum = sum(w1,w2,w3)
w_1n = w1/w_sum
w_2n = w2/w_sum
w_3n = w3/w_sum
## scaling the factors (different scales)
impact_index = impact_index %>%
  mutate(fluency_scaled = scale(fluency_score)[,1],
         adoption_scaled = scale(adoption_score)[,1],
         adaptation_scaled = scale(adaptation_score)[,1],
         impact = w_1n*fluency_scaled+w_2n*adoption_scaled+w_3n*adaptation_scaled,
         impact_scaled = scales::rescale(impact,to = c(0,100)),
         impact_group = ifelse(impact_scaled < quantile(impact_scaled, 0.25, na.rm = TRUE), "Minimal impact", ifelse(impact_scaled >= quantile(impact_scaled, 0.25, na.rm = TRUE) & impact_scaled < quantile(impact_scaled, 0.5, na.rm = TRUE), "Moderate impact", ifelse(impact_scaled >= quantile(impact_scaled, 0.5, na.rm = TRUE) & impact_scaled < quantile(impact_scaled, 0.75, na.rm = TRUE), "Substantial impact","Extensive impact"))),
         ID = rep(1:nrow(.))) 

```

### subgroup analysis on impact index ###

```{r}
design1 = as_survey(impact_index, 
                          id = ID, 
                          weights = POSTWT)

overall_impact = design1 %>%
  group_by(impact_group) %>%
  summarise(proportion = survey_prop(),
            n = survey_total())
sum(overall_impact$n)
svychisq(~impact_group+Age, design1, statistic= "Chisq", na.rm=TRUE)

#For t-test
design2= svydesign(ids= ~ID, weights= ~POSTWT, data= impact_index)
svyttest(impact_scaled~Age, design= design2)
age_by_fed = design1 %>%
  group_by(Age, Fed) %>%
  summarise(sc = survey_mean(impact_scaled, vartype = c("se", "ci"))) %>%
  filter(!is.na(Age)) %>%
  filter(!is.na(Fed))
impact_index_agency_full = na.omit(impact_index_agency)
age_by_fedplt = ggplot(impact_index_agency_full, aes(x = Fed, y = impact_scaled, fill = Age)) +
  geom_boxplot(position = position_dodge(width = 0.8), width = 0.6, outlier.shape = 1)  +
  scale_x_discrete(
    name = "Duration in Federal Government",
    labels = c("1" = "10 years or less", "2" = "11-20 years", "3" = "Over 20 years")
  ) +
  scale_fill_discrete(
    name = "Age",
    labels = c("1" = "Under 40 years", "2" = "40 or older")
  ) +
  labs(
    y = "Mean AI Impact score (95% CI)"
    #title = "AI Impact Scores by duration in Federal Government, stratified by age group"
  ) +
  theme_minimal() 
ggsave("age_by_fed_impact_score.png", age_by_fedplt, dpi = 300)
##Significant

#by Sup
svychisq(~impact_group+Sup, design1, statistic= "Chisq", na.rm=TRUE)

#For t-test
svyttest(impact_scaled~Sup, design= design2)

#by Fed
svychisq(~impact_group+Fed, design1, statistic= "Chisq", na.rm=TRUE)

#For t-test
t1 = svyttest(impact_scaled ~ Fed, design = subset(design2, Fed %in% c("1","2")))
t2 = svyttest(impact_scaled ~ Fed, design = subset(design2, Fed %in% c("1","3")))
t3 = svyttest(impact_scaled ~ Fed, design = subset(design2, Fed %in% c("2","3")))
p_adj = p.adjust(c(t1[["p.value"]][["Fed2"]],t2[["p.value"]][["Fed3"]],t3[["p.value"]][["Fed3"]]), method = "bonferroni")

```

## Group 31 agencies based on: Size of the agency, Industry and sector.

```{r}
impact_index_agency = left_join(impact_index,agency_code,by = c("agency" = "CODE"))
## BY SIZE
design3 = as_survey(impact_index_agency, 
                          id = ID, 
                          weights = POSTWT)
overall_impactscore_agency1 = design3 %>%
  group_by(SIZE) %>%
  summarise(impact_score = survey_mean(impact_scaled),
            n = survey_total())

overall_impactscore_agency2 = design3 %>%
  group_by(impact_group,SIZE) %>%
  summarise(impact_score = survey_mean(impact_scaled),
            n = survey_total())
## by sector
overall_impactscore_agency_sector1 = design3 %>%
  group_by(SECTOR) %>%
  summarise(impact_score = survey_mean(impact_scaled),
            n = survey_total())

overall_impactscore_agency_sector2 = design3 %>%
  group_by(impact_group,SECTOR) %>%
  summarise(impact_score = survey_mean(impact_scaled),
            n = survey_total())
overall_impactscore = design3 %>%
  group_by(impact_group) %>%
  summarise(impact_score = survey_mean(impact_scaled),
            n = survey_total())
overall_impactscore = overall_impactscore %>%
  mutate(lci = impact_score - 1.96*impact_score_se,
         uci = impact_score + 1.96*impact_score_se)

#### tests
#For t-test
t.size1 = svyttest(impact_scaled ~ SIZE, design = subset(design3, SIZE %in% c("Large","Medium")))
t.size2 = svyttest(impact_scaled ~ SIZE, design = subset(design3, SIZE %in% c("Large","Very Large")))
t.size3 = svyttest(impact_scaled ~ SIZE, design = subset(design3, SIZE %in% c("Medium","Very Large")))
p_adj.size = p.adjust(c(t.size1[["p.value"]][["SIZEMedium"]],t.size2[["p.value"]][["SIZEVery Large"]],t.size3[["p.value"]][["SIZEVery Large"]]), method = "bonferroni")

lm_sector = svyglm(impact_scaled~SECTOR, design3)
regTermTest(lm_sector, ~SECTOR)

## Prepare horizontal barplots for size and sector
overall_impactscore_agency1$SIZE= factor(overall_impactscore_agency1$SIZE, levels = c("Very Large", "Large","Medium" ))
size_plot = ggplot(overall_impactscore_agency1[,1:2], aes(x = SIZE, y = impact_score)) +
  geom_col(fill = "steelblue", width = 0.5) + coord_flip() + labs (x = "Size of Agencies", y = "Mean Impact Score") + theme_minimal()
sector_plot = ggplot(overall_impactscore_agency_sector1[,1:2], aes(x = SECTOR, y = impact_score)) +
  geom_col(fill = "steelblue", width = 0.5) + coord_flip() + labs (x = "Agencies by sector", y = "Mean Impact Score") + theme_minimal()

ggsave("impact_scores_by_agency_size.png", size_plot,  dpi = 300)
ggsave("impact_scores_by_agency_sector.png", sector_plot,  dpi = 300)
```

